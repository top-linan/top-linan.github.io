---
permalink: /projects/
title: "Projects"
layout: single
author_profile: true
---

<style>
  .ap-accordion summary { cursor: pointer; font-weight: 600; list-style: none; padding: .35rem 0; }
  .ap-accordion summary::-webkit-details-marker { display: none; }
  .ap-accordion summary::before { content: "▶"; display: inline-block; margin-right: .5rem; transition: transform .15s ease; }
  .ap-accordion details[open] > summary::before { transform: rotate(90deg); }

  .ap-accordion details { margin-bottom: .9rem; }
  .ap-accordion .meta { opacity:.75; font-weight: 400; margin-left:.25rem; }
  .ap-accordion .ap-teaser {
    display:block; margin-top:.15rem; font-weight:400; opacity:.88; line-height:1.35; font-size:.95rem;
    overflow:hidden; display:-webkit-box; -webkit-line-clamp:2; -webkit-box-orient:vertical; /* 两行省略 */
  }
  .ap-accordion .content { margin: .6rem 0 1rem 0; }        /* 去掉整体左缩进 */
  .ap-accordion .content ul,
  .ap-accordion .content ol { margin: .35rem 0 .75rem 0; padding-left: 1rem; }
</style>

<div class="ap-accordion">

  <details>
    <summary>
      Image Matching Challenge 2025 (Kaggle) <span class="meta">· 04–06/2025</span>
      <span class="ap-teaser">Aimed to construct a complete system of image matching and 3D reconstruction inference that can predict camera’s extrinsic parameters and scene affiliation in different scenarios</span>
    </summary>
    <div class="content">
      <ul>
        <li>Utilized FAISS cosine similarity retrieval, based on DINOv2 and CLIP global features, to generate candidate image pairs, ensuring coverage of matched pairs under cross-view and cross-illumination conditions</li>
        <li>Employed ALIKED to extract local key points and descriptors, combined with LightGlue for efficient matching; implemented a fallback to LoFTR when matched points are insufficient, boosting recall by over 15% in scenes with weak textures or repetitive structures</li>
        <li>Adopted PyCOLMAP for incremental mapping to estimate camera rotation matrices and translation vectors, while automatically performing scene clustering to ensure mapping purity and robustness</li>
        <li>Designed a mechanism for parameter tuning and caching (including SIM threshold, number of feature points, and fallback strategy) to significantly reduce inference time while maintaining accuracy; persist intermediate results in HDF5 supported resumable execution</li>
        <li>Implemented an automated submission module that writes the cluster, R, and t into a submission.csv file compliant with competition specifications; the coverage and localization accuracy on the local validation set remained stable and met the requirements for submission</li>
      </ul>
    </div>
  </details>

  <details>
    <summary>
      BYU - Locating Bacterial Flagellar Motors 2025 (Kaggle) <span class="meta">· 04–06/2025</span>
      <span class="ap-teaser">Aimed to precisely localize bacterial flagellar motors in 3D electron tomographic images reconstructed from 2D projections with significant noise and large variations</span>
    </summary>
    <div class="content">
      <ul>
        <li>Constructed a two-stage inference pipeline: YOLOv8/YOLO11 + SAHI + multi-resolution TTA for candidate points; then rotation + zoomed cropping, Midpoint Reasoning, and Bypass Logic for refinement and acceleration</li>
        <li>Trained YOLOv8l/YOLO11l with official and externally corrected datasets; additionally trained a localized model using random cropping to improve robustness on small regions</li>
        <li>Performed model ensembling and built multiple submission configs to explore SAHI on/off, different scaling (z1.5/z2/z3), and parallel pipelines</li>
      </ul>
    </div>
  </details>

  <details>
    <summary>
      Construction of Large Language Model Inference System <span class="meta">· 02–06/2025</span>
      <span class="ap-teaser">Built a high-accuracy LLM inference system for complex natural science MCQs, with multi-model integration and RAG to boost accuracy and speed</span>
    </summary>
    <div class="content">
      <ul>
        <li>Multi-model architecture (Mistral-7B, Yi-34B, LLaMA 2); zero/few-shot + SFT with H2O LLM Studio → >10% accuracy gain in physics/biology</li>
        <li>LoRA fine-tuning + cached past_key_values → 60% faster inference</li>
        <li>RAG + LangChain with 60M-paragraph corpus and FAISS retrieval; multi-round prompt templates</li>
        <li>Confidence integration with TF-IDF re-ranking and embedding similarity → Top-3 hit 93%; ensemble +15% vs single model</li>
      </ul>
    </div>
  </details>

  <details>
    <summary>
      Identification of Offensive Language in Chinese Social Media Environment <span class="meta">· 10–12/2024</span>
      <span class="ap-teaser">Built a deep-learning system to detect implicit and explicit offensive remarks in Chinese social media</span>
    </summary>
    <div class="content">
      <ul>
        <li>Collected/cleaned/annotated data; curated COLD, ToxiCN, ToxiCloakCN datasets</li>
        <li>Trained LSTM, BERT, RoBERTa; selected RoBERTa with 78.54% accuracy for complex language</li>
        <li>Evaluated via Accuracy, ROC-AUC, F1; iteratively optimized</li>
      </ul>
    </div>
  </details>

  <details>
    <summary>
      Predictive Analysis of Diamond Prices <span class="meta">· 05–06/2024</span>
      <span class="ap-teaser">Built a high-precision regression model on 5k diamond transactions with strong validation metrics</span>
    </summary>
    <div class="content">
      <ul>
        <li>Data cleaning, feature engineering, Box-Cox transformations</li>
        <li>Exploratory visualization; identified multicollinearity; improved predictions</li>
        <li>Stepwise regression + cross-validation → R² = 0.9853, CV RMSE = 0.1308</li>
        <li>Residual independence, normality, homoscedasticity tests passed</li>
      </ul>
    </div>
  </details>

  <details>
    <summary>
      Processing and Analyzing of Earthquake Data from 1900 to 2023 <span class="meta">· 03–05/2023</span>
      <span class="ap-teaser">Processed global long-series earthquake data with Hadoop/Spark; analyzed spatiotemporal patterns and hotspots</span>
    </summary>
    <div class="content">
      <ul>
        <li>Large-scale storage and parallel computing with Hadoop/Spark</li>
        <li>Cleaning, time standardization, reverse geocoding for precise locations</li>
        <li>Visualized hotspots and key events (Plotly, WordCloud) to support risk prediction</li>
      </ul>
    </div>
  </details>

</div>
