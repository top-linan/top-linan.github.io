---
permalink: /
title: "Projects"
layout: single
author_profile: true
---

## Projects

### Construction of Large Language Model Inference System  
*02–06/2025*  

Aimed to build a high-accuracy large language model inference system to answer complex natural science multiple-choice questions generated by GPT-3.5.

- Built a multi-model architecture based on open-source models such as **Mistral-7B, Yi-34B, and LLaMA 2**, using Zero-shot, Few-shot, and SFT fine-tuning strategies (with H2O LLM Studio), achieving >10% accuracy improvement in physics/biology domains.  
- Used **LoRA** fine-tuning and cached `past_key_values`, increasing inference speed by **60%**.  
- Integrated **RAG** and LangChain with a **60M-paragraph Wikipedia corpus**, developed a FAISS vector retrieval system, and designed multi-round Prompt templates.  
- Implemented confidence integration and methods such as **TF-IDF re-ranking** and **embedding similarity**, raising Top-3 hit rate to **93%**; integrated model was **15%** more accurate than any single model.

---

### Identification of Offensive Language in Chinese Social Media Environment  
*10–12/2024*  

Aimed to build an automated detection system for implicit/explicit offensive remarks in Chinese social media.

- Collected, cleaned, and annotated Chinese datasets (**COLD, ToxiCN, ToxiCloakCN**).  
- Trained **LSTM, BERT, and RoBERTa** models; final **RoBERTa** model reached **78.54% accuracy**, performing robustly on complex language.  
- Evaluated models via **Accuracy, ROC-AUC, F1-score**, selecting RoBERTa as optimal.

---

### Predictive Analysis of Diamond Prices  
*05–06/2024*  

Used Python and R to model and analyze 5000 diamond transaction records, aiming for high-precision price prediction.

- Performed data cleaning, feature engineering, and **Box-Cox transformation**.  
- Identified multicollinearity via visualization, improved prediction accuracy.  
- Applied **stepwise regression** + **cross-validation** → final model: **R²=0.9853**, **CV RMSE=0.1308**.  
- Passed regression assumption tests (residual independence, normality, homoscedasticity).

---

### Processing and Analyzing Earthquake Data (1900–2023)  
*03–05/2023*  

Applied big data and distributed computing for seismic data analysis and risk insights.

- Used **Hadoop/Spark** for storage & parallel processing of long time-series earthquake data.  
- Performed data cleaning, standardized time formats, applied reverse geocoding for geographic info.  
- Analyzed spatiotemporal patterns and visualized results with **Plotly** and **WordCloud**.



